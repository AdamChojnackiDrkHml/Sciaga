Mamy udowodnić nierówność *Cantelli'ego*.
Dla zmiennej losowej $X$ z $\mathbb{E}[X] = m$ i $Var[X] = \sigma^{2}$ i $\alpha \geq 0$

$$
Pr(X - m \geq \alpha) \leq \frac{\sigma^{2}}{\sigma^{2}+\alpha^{2}}
$$

Dla ułatwienia rachunków, podstawmy $Y = X - m$, wtedy $\mathbb{E}[Y] = 0$ i $Var[Y] = \sigma^{2}$
Weźmy również dowolne $u \geq 0$.
I lecimy z rachunkami:

$$
\begin{align*}
\Pr(X-m \geq \alpha) &= \Pr(Y \geq \alpha)\\
&= \Pr(Y + u \geq \alpha + u)\\
&\leq \Pr((Y+u)^{2} \geq (\alpha + u)^{2})\\
&\leq \frac{\mathbb{E}[(Y+u)^{2}]}{(\alpha + u)^{2}} \text{//z Markova}\\
&= \frac{\mathbb{E}[Y^{2}] + 2u\mathbb{E}[Y] + u^{2}}{(\alpha + u)^{2}}\\
&= \frac{\mathbb{E}[(X - m)^{2}]+u^{2}}{(\alpha + u)^{2}}\\
&= \frac{\sigma^{2}+ u^{2}}{(\alpha + u)^{2}} = f(u)
\end{align*}
$$

Widzimy więc, że nasze p-p jest ograniczone przez $f(u)$. Zminimalizujemy ją teraz, żeby nierówność była jak najbardziej ścisła.

$$
\begin{align*}
\frac{\partial}{\partial u} f(u) &= \frac{\partial}{\partial u}\frac{\sigma^{2}+ u^{2}}{(\alpha + u)^{2}}\\
&= \frac{2u(\alpha + u)^{2} - (\sigma^{2} + u^{2})(2\alpha + 2u)}{(\alpha + u)^{4}}\\
&= \frac{2u\alpha^{2} + 2u^{2}\alpha - 2\sigma^{2}\alpha - 2\sigma^{2}u}{(\alpha + u)^{4}}\\
&= \frac{2u\alpha - 2\sigma^{2}}{(\alpha + u)^{4}}
\end{align*}
$$

Wyraźnie widać, że $f(u_{0}) = 0$, dla $u_{0} = \frac{\sigma^{2}}{\alpha}$
Podstawmy więc $u_{0}$ do naszego ograniczenia.

$$
\begin{align*}
\Pr(X-m \geq \alpha) &\leq \frac{\sigma^{2}+ u^{2}}{(\alpha + u)^{2}}\\
&= \frac{\sigma^{2} + \frac{\sigma^{4}}{\alpha^{2}}}{\left(\alpha + \frac{\sigma^{2}}{\alpha}\right)^{2}}\\
&= \frac{\sigma^{2} \frac{1}{\alpha^{2}}(\alpha^{2} + \sigma^{2})}{\frac{1}{\alpha^{2}}(\alpha^{2}+\sigma^{2})^{2}}\\
&= \frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}}
\end{align*}
$$

Co należało udowodnić.

Teraz udowodnimy punkt drugi:

$$
\Pr(|X - m| \geq \alpha) \leq 2\frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}}
$$

Zauważmy że:

$$
\begin{align*}
\Pr(|X - m| \geq \alpha) &= \Pr(X - m \geq \alpha \lor X -m \leq -\alpha)\\
&= \Pr(X -m \geq \alpha) + \Pr(X-m \leq -\alpha)
\end{align*}
$$

Pierwszy case mamy, w przypadku drugiego, ustalmy $\beta = -\alpha > 0$ oraz $Y = m - X$.

$$
\Pr(X - m \leq \beta) = \Pr(-Y \leq \beta) = \Pr(Y \geq \alpha) \leq \frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}}
$$

Zatem:
$$
\begin{align*}
\Pr(|X-m| \geq \alpha) &= Pr(X-m \leq \alpha) + \Pr(X - m \leq -\alpha)\\
&\leq \frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}} + \frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}}\\
&= 2 \frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}}
\end{align*}
$$

Dla jednostronnych ograniczeń, *Cantelli* jest lepszy, ponieważ *Chebyshev* da nam maksymalnie $\frac{\sigma^{2}}{\alpha^{2}}$.
Natomiast w przypadku dwustronnych ograniczeń, *Cantelli* jest gorszy, przez $2$ z iloczynie.

No i punkt 3. 
Mamy zmienną losową $X$, przyjmującą jedną z dwóch wartości z p-p $p$. Bez straty ogólności, przyjmiemy, że jest to rozkład *Bernoulli'ego*, z wartościami $1$ i $0$. Wiemy, że $\mathbb{E}[X] = p$ i $Var[X] = p(1-p)$.

Ustalamy $\alpha = 1-p$ i bierzemy nierówność *Cantelli'ego*.

$$
\begin{align*}
\Pr(X - \mu \geq \alpha) &\leq \frac{\sigma^{2}}{\alpha^{2}+\sigma^{2}}\\
&= \frac{p(1-p)}{(1-p)^{2}+ p(1-p)} \\
&= \frac{p}{1-p+p} \\
&= \frac{1}{p}
\end{align*}
$$

Znajdźmy teraz prawdziwą wartość prawdopodobieństwa:

$$
\begin{align*}
\Pr(X - \mu \geq 1-p) &= \Pr(X - p \geq 1 - p)\\
&= \Pr(X \geq 1)\\
&= 1
\end{align*}
$$
